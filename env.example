# Copy to .env and configure

# =============================================================================
# LLM Configuration (Factory Pattern - OpenAI default)
# =============================================================================
# Provider: "openai" (default, cloud) or "qwen" (local, requires GPU)
LLM_PROVIDER=openai

# OpenAI Settings (default provider)
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
# OPENAI_BASE_URL=  # Optional: for OpenAI-compatible APIs

# Qwen Settings (local fallback - requires GPU with bitsandbytes)
# QWEN_MODEL_ID=Qwen/Qwen2.5-0.5B-Instruct

# =============================================================================
# Model Service (Separated Architecture)
# =============================================================================
# Set USE_MODEL_SERVICE=true to call external model service instead of local models
# This enables lightweight app containers that scale independently from GPU inference
USE_MODEL_SERVICE=false
MODEL_SERVICE_URL=http://localhost:8001

# =============================================================================
# Database
# =============================================================================
DATABASE_URL=postgresql://docker:docker@localhost:5432/judex

# =============================================================================
# MinIO Object Storage
# =============================================================================
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=judex

# =============================================================================
# Optional Settings
# =============================================================================
# Video processing
# DEFAULT_SAMPLING_FPS=1.0
# SEGMENT_DURATION_SEC=3.0

# Model overrides
# YOLO26_MODEL_ID=openvision/yolo26-s
# WHISPER_MODEL_ID=openai/whisper-small
